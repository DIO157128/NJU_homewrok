

## 问题三

#### 数据处理

根据问题二中的亚类分类结果，我们将高钾、铅钡玻璃分成五个亚类，分别是：

- 高钾_高K2O_-高CaO_SiO2
- 高钾_高K2O_SiO2
- 高钾_低K2O_SiO2
- 铅钡_SiO2
- 铅钡_SiO2_BaO

我们将这五个亚类分别冠以序号1-5，用来将定类数据转化成定量数据以方便训练和预测

同时，我们确保了训练集和测试数据的字段一致。

### BP神经网络预测

为了解决这个分类问题，我们采用BP神经网络，将原数据按照7：3划分为训练集和验证集。同时，由于样本数量有限，我们采用了K折交叉检验的方式来训练数据。在这题中我们取K=4。具体的训练参数如下：

| 参数名              | 参数值   |
| ------------------- | -------- |
| 训练用时            | 2.086s   |
| 数据切分            | 0.7      |
| 数据洗牌            | 是       |
| 交叉验证            | 4        |
| 激活函数            | identity |
| 求解器              | lbfgs    |
| 学习率              | 0.1      |
| L2正则项            | 1        |
| 迭代次数            | 1000     |
| 隐藏第1层神经元数量 | 100      |

#### 敏感性分析

|            | 准确率 | 召回率 | 精确率 | F1    |
| ---------- | ------ | ------ | ------ | ----- |
| 训练集     | 0.977  | 0.977  | 0.978  | 0.976 |
| 交叉验证集 | 0.886  | 0.886  | 0.819  | 0.847 |
| 测试集     | 0.85   | 0.85   | 0.833  | 0.829 |

上表中展示了交叉验证集、训练集和测试集的预测评价指标，通过量化指标来衡量bp神经网络的预测效果。其中，通过交叉验证集的评价指标可以不断调整超参数，以得到可靠稳定的模型。
 ● 准确率：预测正确样本占总样本的比例，准确率越大越好。
 ● 召回率：实际为正样本的结果中，预测为正样本的比例，召回率越大越好。
 ● 精确率：预测出来为正样本的结果中，实际为正样本的比例，精确率越大越好。
 ● F1：精确率和召回率的调和平均，精确率和召回率是互相影响的，虽然两者都高是一种期望的理想情况，然而实际中常常是精确率高、召回率就低，或者召回率低、但精确率高。若需要兼顾两者，那么就可以用F1指标。

#### 预测结果

| 预测结果 | 预测结果概率_1          | 预测结果概率_2           | 预测结果概率_3          | 预测结果概率_4         | 预测结果概率_5           | 二氧化硅(SiO2) | 氧化钠(Na2O) | 氧化钾(K2O) | 氧化钙(CaO) | 氧化镁(MgO) | 氧化铝(Al2O3) | 氧化铁(Fe2O3) | 氧化铜(CuO) | 氧化铅(PbO) |
| -------- | ----------------------- | ------------------------ | ----------------------- | ---------------------- | ------------------------ | -------------- | ------------ | ----------- | ----------- | ----------- | ------------- | ------------- | ----------- | ----------- |
| 3        | 0.005322408149133418    | 0.000024724475061733833  | 0.9942724572723285      | 0.00035049770723456005 | 0.000029912396241549     | 78.45          | 0            | 0           | 6.08        | 1.86        | 7.23          | 2.15          | 2.11        | 0           |
| 4        | 4.157785534680846e-8    | 1.3419992294034085e-8    | 1.15600202971506e-9     | 0.9999974233791488     | 0.0000025204670015057806 | 37.75          | 0            | 0           | 7.63        | 0           | 2.33          | 0             | 0           | 34.3        |
| 5        | 0.000012698827487110965 | 1.698420563718582e-10    | 7.076564311904295e-11   | 0.0031721163875321847  | 0.996815184544373        | 31.95          | 0            | 1.36        | 7.19        | 0.81        | 2.93          | 7.06          | 0.21        | 39.58       |
| 4        | 0.00029411770548460974  | 0.0000014916572022378973 | 2.8673878365699763e-7   | 0.9535105899209974     | 0.046193513977532116     | 35.47          | 0            | 0.79        | 2.89        | 1.05        | 7.07          | 6.45          | 0.96        | 24.28       |
| 4        | 0.0009444205587535357   | 0.0000601474039233089    | 0.017506048425252083    | 0.9810896493324159     | 0.00039973427965518476   | 64.29          | 1.2          | 0.37        | 1.64        | 2.34        | 12.75         | 0.81          | 0.94        | 12.23       |
| 2        | 0.0022763872227195277   | 0.7424433537563029       | 0.2535657821406959      | 0.00171431953618552    | 1.5734409619672318e-7    | 93.17          | 0            | 1.35        | 0.64        | 0.21        | 1.52          | 0.27          | 1.73        | 0           |
| 3        | 0.0031835406266739062   | 0.1809664208276103       | 0.8107152943663312      | 0.005134178350079639   | 5.658293050633e-7        | 90.83          | 0            | 0.98        | 1.12        | 0           | 5.06          | 0.24          | 1.17        | 0           |
| 4        | 0.0003240892560999241   | 0.000006481089653635887  | 0.000032588605480614804 | 0.9815060180224939     | 0.018130823026272        | 51.12          | 0            | 0.23        | 0.89        | 0           | 2.12          | 0             | 9.01        | 21.24       |
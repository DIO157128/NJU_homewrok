标题,类别,ACM Ref
Towards a decision-making structure for selecting a research design in empirical software engineering,other/can not judge,"Claes Wohlin and Aybüke Aurum. 2015. Towards a decision-making structure for selecting a research design in empirical software engineering. Empirical Softw. Engg. 20, 6 (December  2015), 1427–1455. https://doi.org/10.1007/s10664-014-9319-7"
A framework and architecture for rapid software development: a success story,Case Studies,"Manuel J. Moreno-Lizaranzu and Federico Cuesta. 2015. A framework and architecture for rapid software development: a success story. Empirical Softw. Engg. 20, 6 (December 2015), 1456–1485. https://doi.org/10.1007/s10664-014-9320-1"
A large study on the effect of code obfuscation on the quality of java code,Action Research,"Mariano Ceccato, Andrea Capiluppi, Paolo Falcarin, and Cornelia Boldyreff. 2015. A large study on the effect of code obfuscation on the quality of java code. Empirical Softw. Engg. 20, 6 (December  2015), 1486–1524. https://doi.org/10.1007/s10664-014-9321-0"
How product owner teams scale agile methods to large distributed enterprises,Expert Opinions,"Julian M. Bass. 2015. How product owner teams scale agile methods to large distributed enterprises. Empirical Softw. Engg. 20, 6 (December  2015), 1525–1557. https://doi.org/10.1007/s10664-014-9322-z"
Recommending reference API documentation,Controlled Experiments,"Martin P. Robillard and Yam B. Chhetri. 2015. Recommending reference API documentation. Empirical Softw. Engg. 20, 6 (December  2015), 1558–1586. https://doi.org/10.1007/s10664-014-9323-y"
A Large-Scale Empirical Study of the Relationship between Build Technology and Build Maintenance,Case Studies,"Build systems specify how source code is translated into deliverables. They require continual maintenance as the system they build evolves. This build maintenance can become so burdensome that projects switch build technologies, potentially having to rewrite thousands of lines of build code. We aim to understand the prevalence of different build technologies and the relationship between build technology and build maintenance by analyzing version histories in a corpus of 177,039 repositories spread across four software forges, three software ecosystems, and four large-scale projects. We study low-level, abstraction-based, and framework-driven build technologies, as well as tools that automatically manage external dependencies. We find that modern, framework-driven build technologies need to be maintained more often and these build changes are more tightly coupled with the source code than low-level or abstraction-based ones. However, build technology migrations tend to coincide with a shift of build maintenance work to a build-focused team, deferring the cost of build maintenance to them."
"Case studies synthesis: a thematic, cross-case, and narrative synthesis worked example",Action Research,"Daniela S. Cruzes, Tore Dybå, Per Runeson, and Martin Höst. 2015. Case studies synthesis: a thematic, cross-case, and narrative synthesis worked example. Empirical Softw. Engg. 20, 6 (December  2015), 1634–1665. https://doi.org/10.1007/s10664-014-9326-8"
Link analysis algorithms for static concept location: an empirical assessment,Controlled Experiments,"Giuseppe Scanniello, Andrian Marcus, and Daniele Pascale. 2015. Link analysis algorithms for static concept location: an empirical assessment. Empirical Softw. Engg. 20, 6 (December  2015), 1666–1720. https://doi.org/10.1007/s10664-014-9327-7"
Software requirements prioritization and selection using linguistic tools and constraint solvers--a controlled experiment,Controlled Experiments,"Jason Mczara, Shahryar Sarkani, Thomas Holzer, and Timothy Eveleigh. 2015. Software requirements prioritization and selection using linguistic tools and constraint solvers--a controlled experiment. Empirical Softw. Engg. 20, 6 (December  2015), 1721–1761. https://doi.org/10.1007/s10664-014-9334-8"
Optimising agile development practices for the maintenance operation: nine heuristics,other/can not judge,"Lise Tordrup Heeager and Jeremy Rose. 2015. Optimising agile development practices for the maintenance operation: nine heuristics. Empirical Softw. Engg. 20, 6 (December  2015), 1762–1784. https://doi.org/10.1007/s10664-014-9335-7"
Charting the API minefield using software telemetry data,Controlled Experiments,"Maria Kechagia, Dimitris Mitropoulos, and Diomidis Spinellis. 2015. Charting the API minefield using software telemetry data. Empirical Softw. Engg. 20, 6 (December  2015), 1785–1830. https://doi.org/10.1007/s10664-014-9343-7"
An empirical comparison of model-based and capture and replay approaches for performance testing,Controlled Experiments,"Elder Macedo Rodrigues, Flávio Moreira De Oliveira, Leandro Teodoro Costa, Maicon Bernardino, Avelino Francisco Zorzo, Simone Rocio Senger Souza, and Rodrigo Saad. 2015. An empirical comparison of model-based and capture and replay approaches for performance testing. Empirical Softw. Engg. 20, 6 (December  2015), 1831–1860. https://doi.org/10.1007/s10664-014-9337-5"
"The kanban approach, between agility and leanness: a systematic review",Surveys,"Osama Al-Baik and James Miller. 2015. The kanban approach, between agility and leanness: a systematic review. Empirical Softw. Engg. 20, 6 (December  2015), 1861–1897. https://doi.org/10.1007/s10664-014-9340-x"
Semi-automatic selection of primary studies in systematic literature reviews: is it reasonable?,Controlled Experiments,"The systematic review (SR) is a methodology used to find and aggregate all relevant existing evidence about a specific research question of interest. One of the activities associated with the SR process is the selection of primary studies, which is a time consuming manual task. The quality of primary study selection impacts the overall quality of SR. The goal of this paper is to propose a strategy named ""Score Citation Automatic Selection"" (SCAS), to automate part of the primary study selection activity. The SCAS strategy combines two different features, content and citation relationships between the studies, to make the selection activity as automated as possible. Aiming to evaluate the feasibility of our strategy, we conducted an exploratory case study to compare the accuracy of selecting primary studies manually and using the SCAS strategy. The case study shows that for three SRs published in the literature and previously conducted in a manual implementation, the average effort reduction was 58.2 % when applying the SCAS strategy to automate part of the initial selection of primary studies, and the percentage error was 12.98 %. Our case study provided confidence in our strategy, and suggested that it can reduce the effort required to select the primary studies without adversely affecting the overall results of SR."
Introduction to the special issue on software maintenance and evolution research,Systematic Literature Reviews,"Yann-Gaël Guéhéneuc and Tom Mens. 2015. Introduction to the special issue on software maintenance and evolution research. Empirical Softw. Engg. 20, 5 (October   2015), 1193–1197. https://doi.org/10.1007/s10664-015-9398-0"
Supporting and accelerating reproducible empirical research in software evolution and maintenance using TraceLab Component Library,Controlled Experiments,"Bogdan Dit, Evan Moritz, Mario Linares-Vásquez, Denys Poshyvanyk, and Jane Cleland-Huang. 2015. Supporting and accelerating reproducible empirical research in software evolution and maintenance using TraceLab Component Library. Empirical Softw. Engg. 20, 5 (October   2015), 1198–1236. https://doi.org/10.1007/s10664-014-9339-3"
Should I follow this fault localization tool's output?,Controlled Experiments,"Debugging is a crucial yet expensive activity to improve the reliability of software systems. To reduce debugging cost, various fault localization tools have been proposed. A spectrum-based fault localization tool often outputs an ordered list of program elements sorted based on their likelihood to be the root cause of a set of failures (i.e., their suspiciousness scores). Despite the many studies on fault localization, unfortunately, however, for many bugs, the root causes are often low in the ordered list. This potentially causes developers to distrust fault localization tools. Recently, Parnin and Orso highlight in their user study that many debuggers do not find fault localization useful if they do not find the root cause early in the list. To alleviate the above issue, we build an oracle that could predict whether the output of a fault localization tool can be trusted or not. If the output is not likely to be trusted, developers do not need to spend time going through the list of most suspicious program elements one by one. Rather, other conventional means of debugging could be performed. To construct the oracle, we extract the values of a number of features that are potentially related to the effectiveness of fault localization. Building upon advances in machine learning, we process these feature values to learn a discriminative model that is able to predict the effectiveness of a fault localization tool output. In this work, we consider an output of a fault localization tool to be effective if the root cause appears in the top 10 most suspicious program elements. We have evaluated our proposed oracle on 200 faulty versions of Space, NanoXML, XML-Security, and the 7 programs in Siemens test suite. Our experiments demonstrate that we could predict the effectiveness of 9 fault localization tools with a precision, recall, and F-measure (harmonic mean of precision and recall) of up to 74.38 %, 90.00 % and 81.45 %, respectively. The numbers indicate that many ineffective fault localization instances are identified correctly, while only few effective ones are identified wrongly."
How the Apache community upgrades dependencies: an evolutionary study,Case Studies,"Gabriele Bavota, Gerardo Canfora, Massimiliano Di Penta, Rocco Oliveto, and Sebastiano Panichella. 2015. How the Apache community upgrades dependencies: an evolutionary study. Empirical Softw. Engg. 20, 5 (October   2015), 1275–1317. https://doi.org/10.1007/s10664-014-9325-9"
Developer initiation and social interactions in OSS: A case study of the Apache Software Foundation,Case Studies,"Mohammad Gharehyazie, Daryl Posnett, Bogdan Vasilescu, and Vladimir Filkov. 2015. Developer initiation and social interactions in OSS: A case study of the Apache Software Foundation. Empirical Softw. Engg. 20, 5 (October   2015), 1318–1353. https://doi.org/10.1007/s10664-014-9332-x"
Automated prediction of bug report priority using multi-factor analysis,Controlled Experiments,"Yuan Tian, David Lo, Xin Xia, and Chengnian Sun. 2015. Automated prediction of bug report priority using multi-factor analysis. Empirical Softw. Engg. 20, 5 (October   2015), 1354–1383. https://doi.org/10.1007/s10664-014-9331-y"
On rapid releases and software testing: a case study and a semi-systematic literature review,Systematic Literature Reviews,"Mika V. Mäntylä, Bram Adams, Foutse Khomh, Emelie Engström, and Kai Petersen. 2015. On rapid releases and software testing: a case study and a semi-systematic literature review. Empirical Softw. Engg. 20, 5 (October   2015), 1384–1425. https://doi.org/10.1007/s10664-014-9338-4"
Mining system logs to learn error predictors: a case study of a telemetry system,Controlled Experiments,"Barbara Russo, Giancarlo Succi, and Witold Pedrycz. 2015. Mining system logs to learn error predictors: a case study of a telemetry system. Empirical Softw. Engg. 20, 4 (August    2015), 879–927. https://doi.org/10.1007/s10664-014-9303-2"
"Fault density, fault types, and spectra-based fault localization",Action Research,"Nicholas Digiuseppe and James A. Jones. 2015. Fault density, fault types, and spectra-based fault localization. Empirical Softw. Engg. 20, 4 (August    2015), 928–967. https://doi.org/10.1007/s10664-014-9304-1"
An elicitation instrument for operationalising GQM+Strategies (GQM+S-EI),Controlled Experiments,"Kai Petersen, Cigdem Gencel, Negin Asghari, and Stefanie Betz. 2015. An elicitation instrument for operationalising GQM+Strategies (GQM+S-EI). Empirical Softw. Engg. 20, 4 (August    2015), 968–1005. https://doi.org/10.1007/s10664-014-9306-z"
Fostering effective inter-team knowledge sharing in agile software development,Case Studies,"Viviane Santos, Alfredo Goldman, and Cleidson R. B. De Souza. 2015. Fostering effective inter-team knowledge sharing in agile software development. Empirical Softw. Engg. 20, 4 (August    2015), 1006–1051. https://doi.org/10.1007/s10664-014-9307-y"
Are test smells really harmful? An empirical study,Action Research,"Gabriele Bavota, Abdallah Qusef, Rocco Oliveto, Andrea Lucia, and Dave Binkley. 2015. Are test smells really harmful? An empirical study. Empirical Softw. Engg. 20, 4 (August    2015), 1052–1094. https://doi.org/10.1007/s10664-014-9313-0"
Classification model for code clones based on machine learning,Controlled Experiments,"Jiachen Yang, Keisuke Hotta, Yoshiki Higo, Hiroshi Igaki, and Shinji Kusumoto. 2015. Classification model for code clones based on machine learning. Empirical Softw. Engg. 20, 4 (August    2015), 1095–1125. https://doi.org/10.1007/s10664-014-9316-x"
The impact of imperfect change rules on framework API evolution identification: an empirical study,Action Research,"Wei Wu, Adrien Serveaux, Yann-Gaël Guéhéneuc, and Giuliano Antoniol. 2015. The impact of imperfect change rules on framework API evolution identification: an empirical study. Empirical Softw. Engg. 20, 4 (August    2015), 1126–1158. https://doi.org/10.1007/s10664-014-9317-9"
Confounding parameters on program comprehension: a literature survey,Systematic Literature Reviews,"Janet Siegmund and Jana Schumann. 2015. Confounding parameters on program comprehension: a literature survey. Empirical Softw. Engg. 20, 4 (August    2015), 1159–1192. https://doi.org/10.1007/s10664-014-9318-8"
Multi-objective ant colony optimization for requirements selection,Controlled Experiments,"José Sagrado, Isabel M. Águila, and Francisco J. Orellana. 2015. Multi-objective ant colony optimization for requirements selection. Empirical Softw. Engg. 20, 3 (June      2015), 577–610. https://doi.org/10.1007/s10664-013-9287-3"
1600 faults in 100 projects: automatically finding faults while achieving high coverage with EvoSuite,Controlled Experiments,"Gordon Fraser and Andrea Arcuri. 2015. 1600 faults in 100 projects: automatically finding faults while achieving high coverage with EvoSuite. Empirical Softw. Engg. 20, 3 (June      2015), 611–639. https://doi.org/10.1007/s10664-013-9288-2"
Empirical evidence on the link between object-oriented measures and external quality attributes: a systematic literature review,Systematic Literature Reviews,"Ronald Jabangwe, Jürgen Börstler, Darja Smite, and Claes Wohlin. 2015. Empirical evidence on the link between object-oriented measures and external quality attributes: a systematic literature review. Empirical Softw. Engg. 20, 3 (June      2015), 640–693. https://doi.org/10.1007/s10664-013-9291-7"
"Visual GUI testing in practice: challenges, problemsand limitations",Case Studies,"Emil Alégroth, Robert Feldt, and Lisa Ryrholm. 2015. Visual GUI testing in practice: challenges, problemsand limitations. Empirical Softw. Engg. 20, 3 (June      2015), 694–744."
Object-oriented software extensions in practice,Action Research,"Romain Robbes, David Röthlisberger, and Éric Tanter. 2015. Object-oriented software extensions in practice. Empirical Softw. Engg. 20, 3 (June      2015), 745–782. https://doi.org/10.1007/s10664-013-9298-0"
Achieving scalable mutation-based generation of whole test suites,Controlled Experiments,"Gordon Fraser and Andrea Arcuri. 2015. Achieving scalable mutation-based generation of whole test suites. Empirical Softw. Engg. 20, 3 (June      2015), 783–812."
Transfer learning in effort estimation,Controlled Experiments,"Ekrem Kocaguneli, Tim Menzies, and Emilia Mendes. 2015. Transfer learning in effort estimation. Empirical Softw. Engg. 20, 3 (June      2015), 813–843. https://doi.org/10.1007/s10664-014-9300-5"
An experiment on the effectiveness and efficiency of exploratory testing,Action Research,"Wasif Afzal, Ahmad Nauman Ghazi, Juha Itkonen, Richard Torkar, Anneliese Andrews, and Khurram Bhatti. 2015. An experiment on the effectiveness and efficiency of exploratory testing. Empirical Softw. Engg. 20, 3 (June      2015), 844–878. https://doi.org/10.1007/s10664-014-9301-4"
Guest editorial: special section on mining software repositories,Systematic Literature Reviews,"Massimiliano Di Penta and Tao Xie. 2015. Guest editorial: special section on mining software repositories. Empirical Softw. Engg. 20, 2 (April     2015), 291–293. https://doi.org/10.1007/s10664-015-9383-7"
"Towards improving statistical modeling of software engineering data: think locally, act globally!",Surveys,"Nicolas Bettenburg, Meiyappan Nagappan, and Ahmed E. Hassan. 2015. Towards improving statistical modeling of software engineering data: think locally, act globally! Empirical Softw. Engg. 20, 2 (April     2015), 294–335. https://doi.org/10.1007/s10664-013-9292-6"
Understanding the impact of rapid releases on software quality,Expert Opinions,"Foutse Khomh, Bram Adams, Tejinder Dhaliwal, and Ying Zou. 2015. Understanding the impact of rapid releases on software quality. Empirical Softw. Engg. 20, 2 (April     2015), 336–373. https://doi.org/10.1007/s10664-014-9308-x"
Green mining: a methodology of relating software change and configuration to power consumption,Controlled Experiments,"Abram Hindle. 2015. Green mining: a methodology of relating software change and configuration to power consumption. Empirical Softw. Engg. 20, 2 (April     2015), 374–409. https://doi.org/10.1007/s10664-013-9276-6"
Guest editorial: special section on software maintenance and evolution,Systematic Literature Reviews,"Massimiliano Di Penta and Jonathan I. Maletic. 2015. Guest editorial: special section on software maintenance and evolution. Empirical Softw. Engg. 20, 2 (April     2015), 410–412. https://doi.org/10.1007/s10664-015-9382-8"
Do developers benefit from requirements traceability when evolving and maintaining a software system?,Controlled Experiments,"Patrick Mäder and Alexander Egyed. 2015. Do developers benefit from requirements traceability when evolving and maintaining a software system? Empirical Softw. Engg. 20, 2 (April     2015), 413–441. https://doi.org/10.1007/s10664-014-9314-z"
An empirical study on the importance of source code entities for requirements traceability,Action Research,"Nasir Ali, Zohreh Sharafi, Yann-Gaël Guéhéneuc, and Giuliano Antoniol. 2015. An empirical study on the importance of source code entities for requirements traceability. Empirical Softw. Engg. 20, 2 (April     2015), 442–478. https://doi.org/10.1007/s10664-014-9315-y"
Do topics make sense to managers and developers?,Surveys,"Abram Hindle, Christian Bird, Thomas Zimmermann, and Nachiappan Nagappan. 2015. Do topics make sense to managers and developers? Empirical Softw. Engg. 20, 2 (April     2015), 479–515. https://doi.org/10.1007/s10664-014-9312-1"
Modelling the `hurried' bug report reading process to summarize bug reports,Controlled Experiments,"Rafael Lotufo, Zeeshan Malik, and Krzysztof Czarnecki. 2015. Modelling the `hurried' bug report reading process to summarize bug reports. Empirical Softw. Engg. 20, 2 (April     2015), 516–548. https://doi.org/10.1007/s10664-014-9311-2"
Detecting and refactoring code smells in spreadsheet formulas,Controlled Experiments,"Felienne Hermans, Martin Pinzger, and Arie Deursen. 2015. Detecting and refactoring code smells in spreadsheet formulas. Empirical Softw. Engg. 20, 2 (April     2015), 549–575. https://doi.org/10.1007/s10664-013-9296-2"
Studying the relationship between logging characteristics and the code quality of platform software,Controlled Experiments,"Weiyi Shang, Meiyappan Nagappan, and Ahmed E. Hassan. 2015. Studying the relationship between logging characteristics and the code quality of platform software. Empirical Softw. Engg. 20, 1 (Feb 2015), 1–27. https://doi.org/10.1007/s10664-013-9274-8"
Understanding the Influence of User Participation and Involvement on System Success – a Systematic Mapping Study,Surveys,"Ulrike Abelein and Barbara Paech. 2015. Understanding the Influence of User Participation and Involvement on System Success – a Systematic Mapping Study. Empirical Softw. Engg. 20, 1 (Feb 2015), 28–81. https://doi.org/10.1007/s10664-013-9278-4"
HAZOP-based identification of events in use cases: An empirical study,Action Research,"Completeness is one of the main quality attributes of requirements specifications. If functional requirements are expressed as use cases, one can be interested in event completeness. A use case is event complete if it contains description of all the events that can happen when executing the use case. Missing events in any use case can lead to higher project costs. Thus, the question arises of what is a good method of identification of events in use cases and what accuracy and review speed one can expect from it. The goal of this study was to check if (1) HAZOP-based event identification is more effective thanad hocreview and (2) what is the review speed of these two approaches. Two controlled experiments were conducted in order to evaluatead hocapproach and H4U method to event identification. The first experiment included 18 students, while the second experiment was conducted with the help of 82 professionals. In both cases, accuracy and review speed of the investigated methods were measured and analyzed. Moreover, the usage of HAZOP keywords was analyzed. In both experiments, a benchmark specification based on use cases was used. The first experiment with students showed that a HAZOP-based review is more effective in event identification thanad hocreview and this result is statistically significant. However, the reviewing speed of HAZOP-based reviews is lower. The second experiment with professionals confirmed these results. These experiments showed also that event completeness is hard to achieve. It on average ranged from 0.15 to 0.26. HAZOP-based identification of events in use cases is an useful alternative toad hocreviews. It can achieve higher event completeness at the cost of an increase in effort."
A practical guide to controlled experiments of software engineering tools with human participants,other/can not judge,"Amy J. Ko, Thomas D. LaToza, and Margaret M. Burnett. 2015. A practical guide to controlled experiments of software engineering tools with human participants. Empirical Softw. Engg. 20, 1 (Feb 2015), 110–141. https://doi.org/10.1007/s10664-013-9279-3"
An experimental investigation comparing individual and collaborative work productivity when using desktop and cloud modeling tools,Controlled Experiments,"Gregor Polančič, Gregor Jošt, and Marjan Heričko. 2015. An experimental investigation comparing individual and collaborative work productivity when using desktop and cloud modeling tools. Empirical Softw. Engg. 20, 1 (Feb 2015), 142–175. https://doi.org/10.1007/s10664-013-9280-x"
Mining software repair models for reasoning on the search space of automated program fixing,Controlled Experiments,"Matias Martinez and Martin Monperrus. 2015. Mining software repair models for reasoning on the search space of automated program fixing. Empirical Softw. Engg. 20, 1 (Feb 2015), 176–205. https://doi.org/10.1007/s10664-013-9282-8"
UML model refactoring: a systematic literature review,Systematic Literature Reviews,"Mohammed Misbhauddin and Mohammad Alshayeb. 2015. UML model refactoring: a systematic literature review. Empirical Softw. Engg. 20, 1 (Feb 2015), 206–251. https://doi.org/10.1007/s10664-013-9283-7"
Management of community contributions: A case study on the Android and Linux software ecosystems,Controlled Experiments,"Nicolas Bettenburg, Ahmed E. Hassan, Bram Adams, and Daniel M. German. 2015. Management of community contributions: A case study on the Android and Linux software ecosystems. Empirical Softw. Engg. 20, 1 (Feb 2015), 252–289. https://doi.org/10.1007/s10664-013-9284-6"
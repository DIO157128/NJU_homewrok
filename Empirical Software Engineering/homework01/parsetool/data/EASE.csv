标题,类别,ACM Ref
"Robust Statistical Methods: Why, What and How: Keynote",Controlled Experiments,"Barbara Kitchenham. 2015. Robust statistical methods: why, what and how: keynote. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 1, 1–6. https://doi.org/10.1145/2745802.2747956"
Selecting Research Methods for Studying a Participatory Culture,Ethnography,"Margaret-Anne Storey. 2015. Selecting research methods for studying a participatory culture in software development: keynote. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 2, 1–5. https://doi.org/10.1145/2745802.2747957"
Supporting Architecture Documentation: A Comparison of Two Ontologies for Knowledge Retrieval,Controlled Experiments,"Klaas Andries de Graaf, Peng Liang, Antony Tang, and Hans van Vliet. 2015. Supporting architecture documentation: a comparison of two ontologies for knowledge retrieval. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 3, 1–10. https://doi.org/10.1145/2745802.2745804"
Strategies for Consistency Checking on Software Product Lines: A Mapping Study,Systematic Literature Reviews,"Alcemir Rodrigues Santos, Raphael Pereira de Oliveira, and Eduardo Santana de Almeida. 2015. Strategies for consistency checking on software product lines: a mapping study. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 5, 1–14. https://doi.org/10.1145/2745802.2745806"
"Predicting Concurrency Bugs: How Many, What Kind and Where Are They?",Action Research,"Bo Zhou, Iulian Neamtiu, and Rajiv Gupta. 2015. Predicting concurrency bugs: how many, what kind and where are they? In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 6, 1–10. https://doi.org/10.1145/2745802.2745807"
A Cross-Platform Analysis of Bugs and Bug-Fixing in Open Source Projects: Desktop vs. Android vs. IOS,Controlled Experiments,"Bo Zhou, Iulian Neamtiu, and Rajiv Gupta. 2015. A cross-platform analysis of bugs and bug-fixing in open source projects: desktop vs. Android vs. iOS. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 7, 1–10. https://doi.org/10.1145/2745802.2745808"
Applying Clustering to Analyze Opinion Diversity,Surveys,"Mohammad Mahdi Hassan and Martin Blom. 2015. Applying clustering to analyze opinion diversity. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 8, 1–10. https://doi.org/10.1145/2745802.2745809"
Problems and Challenges of User Involvement in Software Development: An Empirical Study,Case Studies,"Didar Zowghi, Francesca da Rimini, and Muneera Bano. 2015. Problems and challenges of user involvement in software development: an empirical study. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 9, 1–10. https://doi.org/10.1145/2745802.2745810"
Fault Density Analysis of Object-Oriented Classes in Presence of Code Clones,Controlled Experiments,"Mahmoud O. Elish and Yasser Al-Ghamdi. 2015. Fault density analysis of object-oriented classes in presence of code clones. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 10, 1–7. https://doi.org/10.1145/2745802.2745811"
On the Effects of Traceability Links in Differently Sized Software Systems,Controlled Experiments,"Muhammad Atif Javed and Uwe Zdun. 2015. On the effects of traceability links in differently sized software systems. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 11, 1–10. https://doi.org/10.1145/2745802.2745812"
Effort Estimation in Agile Software Development: A Survey on the State of the Practice,Surveys,"Muhammad Usman, Emilia Mendes, and Jürgen Börstler. 2015. Effort estimation in agile software development: a survey on the state of the practice. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 12, 1–10. https://doi.org/10.1145/2745802.2745813"
Quality Assessment of Systematic Reviews in Software Engineering: A Tertiary Study,Controlled Experiments,"You Zhou, He Zhang, Xin Huang, Song Yang, Muhammad Ali Babar, and Hao Tang. 2015. Quality assessment of systematic reviews in software engineering: a tertiary study. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 14, 1–14. https://doi.org/10.1145/2745802.2745815"
The Adoption of Capture-Recapture in Software Engineering: A Systematic Literature Review,Systematic Literature Reviews,"Gaoxuan Liu, Guoping Rong, He Zhang, and Qi Shan. 2015. The adoption of capture-recapture in software engineering: a systematic literature review. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 15, 1–13. https://doi.org/10.1145/2745802.2745816"
A Controlled Experiment for the Empirical Evaluation of Safety Analysis Techniques for Safety-Critical Software,Controlled Experiments,"Asim Abdulkhaleq and Stefan Wagner. 2015. A controlled experiment for the empirical evaluation of safety analysis techniques for safety-critical software. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 16, 1–10. https://doi.org/10.1145/2745802.2745817"
Experiences from Using Snowballing and Database Searches in Systematic Literature Studies,Controlled Experiments,"Deepika Badampudi, Claes Wohlin, and Kai Petersen. 2015. Experiences from using snowballing and database searches in systematic literature studies. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 17, 1–10. https://doi.org/10.1145/2745802.2745818"
Analyzing Confidentiality and Privacy Concerns: Insights from Android Issue Logs,other/can not judge,"Sherlock A. Licorish, Stephen G. MacDonell, and Tony Clear. 2015. Analyzing confidentiality and privacy concerns: insights from Android issue logs. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 18, 1–10. https://doi.org/10.1145/2745802.2745819"
Case Consistency: A Necessary Data Quality Property for Software Engineering Data Sets,Controlled Experiments,"Passakorn Phannachitta, Akito Monden, Jacky Keung, and Kenichi Matsumoto. 2015. Case consistency: a necessary data quality property for software engineering data sets. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 19, 1–10. https://doi.org/10.1145/2745802.2745820"
An Empirical Assessment of Bellon's Clone Benchmark,Surveys,"Alan Charpentier, Jean-Rémy Falleri, David Lo, and Laurent Réveillère. 2015. An empirical assessment of Bellon's clone benchmark. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 20, 1–10. https://doi.org/10.1145/2745802.2745821"
Software Metrics for Measuring the Understandability of Architectural Structures: A Systematic Mapping Study,Systematic Literature Reviews,"Srdjan Stevanetic and Uwe Zdun. 2015. Software metrics for measuring the understandability of architectural structures: a systematic mapping study. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 21, 1–14. https://doi.org/10.1145/2745802.2745822"
Support Mechanisms to Conduct Empirical Studies in Software Engineering: A Systematic Mapping Study,Systematic Literature Reviews,"Alex Borges, Waldemar Ferreira, Emanoel Barreiros, Adauto Almeida, Liliane Fonseca, Eudis Teixeira, Diogo Silva, Aline Alencar, and Sergio Soares. 2015. Support mechanisms to conduct empirical studies in software engineering: a systematic mapping study. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 22, 1–14. https://doi.org/10.1145/2745802.2745823"
Systematic Review Toolbox: A Catalogue of Tools to Support Systematic Reviews,Systematic Literature Reviews,"Christopher Marshall and Pearl Brereton. 2015. Systematic review toolbox: a catalogue of tools to support systematic reviews. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 23, 1–6. https://doi.org/10.1145/2745802.2745824"
SESRA: A Web-Based Automated Tool to Support the Systematic Literature Review Process,Systematic Literature Reviews,"Jefferson Seide Molléri and Fabiane Barreto Vavassori Benitti. 2015. SESRA: a web-based automated tool to support the systematic literature review process. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 24, 1–6. https://doi.org/10.1145/2745802.2745825"
On the Effects of Programming and Testing Skills on External Quality and Productivity in a Test-Driven Development Context,other/can not judge,"Davide Fucci, Burak Turhan, and Markku Oivo. 2015. On the effects of programming and testing skills on external quality and productivity in a test-driven development context. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 25, 1–6. https://doi.org/10.1145/2745802.2745826"
Tools to Support Systematic Reviews in Software Engineering: A Cross-Domain Survey Using Semi-Structured Interviews,Surveys,"Christopher Marshall, Pearl Brereton, and Barbara Kitchenham. 2015. Tools to support systematic reviews in software engineering: a cross-domain survey using semi-structured interviews. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 26, 1–6. https://doi.org/10.1145/2745802.2745827"
Analyzing Program Readability Based on WordNet,Action Research,"Yangchao Liu, Xiaobing Sun, and Yucong Duan. 2015. Analyzing program readability based on WordNet. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 27, 1–2. https://doi.org/10.1145/2745802.2745837"
Understanding Differences in Process Perspectives between Developers and Acquirers in Off-the-Shelf-Based Custom Software Projects Undertaken in Indonesia,Surveys,"Dana Sulistiyo Kusumo and Ariadi Nugroho. 2015. Understanding differences in process perspectives between developers and acquirers in off-the-shelf-based custom software projects undertaken in Indonesia. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 28, 1–6. https://doi.org/10.1145/2745802.2745828"
The Impact of Students' Skills and Experiences on Empirical Results: A Controlled Experiment with Undergraduate and Graduate Students,Controlled Experiments,"Marian Daun, Andrea Salmon, Thorsten Weyer, and Klaus Pohl. 2015. The impact of students' skills and experiences on empirical results: a controlled experiment with undergraduate and graduate students. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 29, 1–6. https://doi.org/10.1145/2745802.2745829"
"Environment Modeling in Model-Based Testing: Concepts, Prospects and Research Challenges: A Systematic Literature Review",Systematic Literature Reviews,"Faezeh Siavashi and Dragos Truscan. 2015. Environment modeling in model-based testing: concepts, prospects and research challenges: a systematic literature review. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 30, 1–6. https://doi.org/10.1145/2745802.2745830"
Identifying the Factors That Influence Task Allocation in Global Software Development: Preliminary Results,Systematic Literature Reviews,"Sajjad Mahmood, Sajid Anwer, Mahmood Niazi, Mohammad Alshayeb, and Ita Richardson. 2015. Identifying the factors that influence task allocation in global software development: preliminary results. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 31, 1–6. https://doi.org/10.1145/2745802.2745831"
Using Blind Analysis for Software Engineering Experiments,Controlled Experiments,"Boyce Sigweni and Martin Shepperd. 2015. Using blind analysis for software engineering experiments. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 32, 1–6. https://doi.org/10.1145/2745802.2745832"
Towards an Automation of the Traceability of Bugs from Development Logs: A Study Based on Open Source Software,Action Research,"Bilyaminu Auwal Romo and Andrea Capiluppi. 2015. Towards an automation of the traceability of bugs from development logs: a study based on open source software. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 33, 1–6. https://doi.org/10.1145/2745802.2745833"
Customer Satisfaction Feedback in an IT Outsourcing Company: A Case Study on the Insigma Hengtian Company,Case Studies,"Xin Xia, David Lo, Jingfan Tang, and Shanping Li. 2015. Customer satisfaction feedback in an IT outsourcing company: a case study on the insigma Hengtian company. In Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering (EASE '15). Association for Computing Machinery, New York, NY, USA, Article 34, 1–5. https://doi.org/10.1145/2745802.2745834"